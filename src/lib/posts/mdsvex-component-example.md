---
title: "Ti·∫øn tr√¨nh v√† lu·ªìng"
date: "2023-04-28"
updated: "2023-04-28"
categories:
  - "Phancung"
  - "thread"
  - "process"
  - "Chatgpt"
coverImage: "https://images.viblo.asia/0aac891f-f99f-47ae-94a9-c38135c72256.png"
coverWidth: 16
coverHeight: 9
excerpt: B√†i t·∫≠p m√¥n H·ªá th·ªëng ph√¢n t√°n ‚Äì T·ªïng h·ª£p ki·∫øn th·ª©c v√† th·ª±c h√†nh
---

<script>
	import Callout from '$lib/components/Callout.svelte';
</script>

*B√†i t·∫≠p m√¥n H·ªá th·ªëng ph√¢n t√°n ‚Äì T·ªïng h·ª£p ki·∫øn th·ª©c v√† th·ª±c h√†nh*

---

## 1. ƒê√°nh gi√° hi·ªáu nƒÉng m√°y t√≠nh c√° nh√¢n

D·ª±a v√†o ki·∫øn th·ª©c b√†i h·ªçc v·ªÅ ti·∫øn tr√¨nh v√† lu·ªìng, em ƒë√£ ki·ªÉm tra c·∫•u h√¨nh c·ªßa m√°y t√≠nh c√° nh√¢n nh∆∞ sau:
![Web v√† ·ª©ng d·ª•ng di ƒë·ªông](https://st.quantrimang.com/photos/image/2024/11/22/kiem-tra-hieu-suat-may-tinh-1.png)


- **CPU**: AMD Ryzen 7700 ‚Äì 8 nh√¢n 12 lu·ªìng
- **GPU**: AMD RX6800 ‚Äì 6GB GDDR6
- **RAM**: 16GB DDR4 ‚Äì Bus 3200MHz

### Gi·∫£i th√≠ch hi·ªáu nƒÉng:
- **CPU nhi·ªÅu lu·ªìng:** 
CPU (b·ªô x·ª≠ l√Ω trung t√¢m) c√≥ nhi·ªÅu lu·ªìng (threads) ƒë·ªìng nghƒ©a v·ªõi vi·ªác n√≥ c√≥ th·ªÉ x·ª≠ l√Ω nhi·ªÅu t√°c v·ª• c√πng l√∫c hi·ªáu qu·∫£ h∆°n. ƒêi·ªÅu n√†y r·∫•t quan tr·ªçng khi ch·∫°y nhi·ªÅu ·ª©ng d·ª•ng c√πng l√∫c ho·∫∑c x·ª≠ l√Ω c√°c t√°c v·ª• ph·ª©c t·∫°p nh∆∞ l·∫≠p tr√¨nh, d·ª±ng video, ho·∫∑c l√†m vi·ªác v·ªõi m√°y ·∫£o. Nhi·ªÅu lu·ªìng s·∫Ω gi√∫p gi·∫£m ƒë·ªô tr·ªÖ v√† tƒÉng kh·∫£ nƒÉng ph·∫£n h·ªìi c·ªßa h·ªá th·ªëng.
- **GPU r·ªùi:** 
GPU r·ªùi (card ƒë·ªì h·ªça ri√™ng bi·ªát, kh√¥ng t√≠ch h·ª£p trong CPU) cung c·∫•p s·ª©c m·∫°nh x·ª≠ l√Ω ƒë·ªì h·ªça cao h∆°n, r·∫•t h·ªØu √≠ch cho thi·∫øt k·∫ø ƒë·ªì h·ªça, ch·ªânh s·ª≠a video, ch∆°i game ho·∫∑c d·ª±ng h√¨nh 3D. Ngo√†i ra, GPU c≈©ng h·ªó tr·ª£ tƒÉng t·ªëc t√≠nh to√°n cho c√°c ·ª©ng d·ª•ng tr√≠ tu·ªá nh√¢n t·∫°o (AI) v√† h·ªçc m√°y (Machine Learning ‚Äì ML), ƒë·∫∑c bi·ªát l√† trong vi·ªác hu·∫•n luy·ªán v√† ch·∫°y m√¥ h√¨nh ·ªü m·ª©c c∆° b·∫£n ƒë·∫øn trung c·∫•p.
- **RAM 16GB:** 
Dung l∆∞·ª£ng RAM l·ªõn (16GB) gi√∫p h·ªá th·ªëng c√≥ ƒë·ªß b·ªô nh·ªõ ƒë·ªÉ v·∫≠n h√†nh m∆∞·ª£t m√† nhi·ªÅu ·ª©ng d·ª•ng c√πng l√∫c, ƒë·∫∑c bi·ªát l√† c√°c ph·∫ßn m·ªÅm n·∫∑ng nh∆∞ tr√¨nh IDE, tr√¨nh duy·ªát v·ªõi nhi·ªÅu tab, c√¥ng c·ª• ƒë·ªì h·ªça, v√† ph·∫ßn m·ªÅm m√°y ·∫£o (nh∆∞ VirtualBox, Docker). RAM l·ªõn gi√∫p gi·∫£m t√¨nh tr·∫°ng ch·∫≠m do h·ªá th·ªëng ph·∫£i s·ª≠ d·ª•ng b·ªô nh·ªõ ·∫£o t·ª´ ·ªï ƒëƒ©a.
---

## 2. C√°c b√†i to√°n ph·ªï bi·∫øn d√πng ƒëa lu·ªìng ho·∫∑c ƒëa ti·∫øn tr√¨nh

Trong th·∫ø gi·ªõi ph·∫ßn m·ªÅm hi·ªán ƒë·∫°i, hi·ªáu nƒÉng lu√¥n l√† y·∫øu t·ªë then ch·ªët. ƒê·ªÉ t·ªëi ∆∞u hi·ªáu su·∫•t, nhi·ªÅu h·ªá th·ªëng s·ª≠ d·ª•ng **ƒëa lu·ªìng ** ho·∫∑c **ƒëa ti·∫øn tr√¨nh ** nh·∫±m khai th√°c tri·ªát ƒë·ªÉ t√†i nguy√™n ph·∫ßn c·ª©ng, ƒë·∫∑c bi·ªát l√† CPU ƒëa nh√¢n. Nh∆∞ng n√™n d√πng k·ªπ thu·∫≠t n√†o cho b√†i to√°n n√†o?. V·∫≠y ttrong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω kh√°m ph√° s·ª± kh√°c bi·ªát gi·ªØa ti·∫øn tr√¨nh v√† lu·ªìng m·ªôt c√°ch chi ti·∫øt.


### üìå ƒêa Lu·ªìng v√† ƒêa Ti·∫øn Tr√¨nh L√† G√¨?
![Web v√† ·ª©ng d·ª•ng di ƒë·ªông](https://nguyentruonglong.net/images/MultithreadingvsMultiprocessing.png)
- **ƒêa lu·ªìng**: Nhi·ªÅu lu·ªìng (threads) c√πng ch·∫°y trong m·ªôt ti·∫øn tr√¨nh, chia s·∫ª b·ªô nh·ªõ chung. Ph√π h·ª£p v·ªõi c√°c t√°c v·ª• nh·∫π, ph·ª• thu·ªôc l·∫´n nhau, ho·∫∑c c·∫ßn t·ªëc ƒë·ªô giao ti·∫øp n·ªôi b·ªô nhanh.
- **ƒêa ti·∫øn tr√¨nh**: M·ªói ti·∫øn tr√¨nh l√† m·ªôt kh√¥ng gian b·ªô nh·ªõ ri√™ng. Ph√π h·ª£p v·ªõi t√°c v·ª• n·∫∑ng, ƒë·ªôc l·∫≠p, ho·∫∑c khi c·∫ßn ƒë·ªô c√°ch ly cao gi·ªØa c√°c ph·∫ßn.

H√£y c√πng ƒëi·ªÉm qua **12 b√†i to√°n ph·ªï bi·∫øn** th∆∞·ªùng √°p d·ª•ng ƒëa lu·ªìng ho·∫∑c ƒëa ti·∫øn tr√¨nh, c√πng v·ªõi v√≠ d·ª• ·ª©ng d·ª•ng th·ª±c t·∫ø.


| STT | B√†i to√°n / ·ª®ng d·ª•ng                          | D√πng ƒëa lu·ªìng / ƒëa ti·∫øn tr√¨nh | ·ª®ng d·ª•ng                             |
|-----|----------------------------------------------|-------------------------------|---------------------------------------------|
| 1   | Web Server x·ª≠ l√Ω nhi·ªÅu request       | ƒêa ti·∫øn tr√¨nh / ƒëa lu·ªìng      | Apache, Nginx                               |
| 2   | Game Engine                                  | ƒêa lu·ªìng                      | Unity, Unreal Engine                        |
| 3   | Ph√¢n t√≠ch d·ªØ li·ªáu l·ªõn              | ƒêa ti·∫øn tr√¨nh                 | Hadoop, Spark                               |
| 4   | Rendering video                              | ƒêa lu·ªìng                      | Adobe Premiere, Blender                     |
| 5   | Download nhi·ªÅu file song song            | ƒêa lu·ªìng                      | Tr√¨nh duy·ªát, IDM                            |
| 6   | AI/ML training model                         | ƒêa ti·∫øn tr√¨nh                 | TensorFlow, PyTorch                         |
| 7   | Anti-virus scan                              | ƒêa ti·∫øn tr√¨nh                 | Avast, Kaspersky                            |
| 8   | Chat server                                   | ƒêa lu·ªìng                      | WhatsApp server, Discord backend            |
| 9   | Compiler (bi√™n d·ªãch nhi·ªÅu file)     | ƒêa ti·∫øn tr√¨nh                 | GCC, Clang                                  |
| 10  | Simulation v·∫≠t l√Ω                        | ƒêa lu·ªìng                      | NASA, game v·∫≠t l√Ω                           |
| 11  | Database server                              | ƒêa ti·∫øn tr√¨nh / ƒëa lu·ªìng      | MySQL, PostgreSQL                           |
| 12  | Virtual Machine / Docker                     | ƒêa ti·∫øn tr√¨nh                 | VMware, Docker                              |

---

## 3. Khi n√†o d√πng Thread, khi n√†o d√πng Process, khi n√†o d√πng c·∫£ hai

Ti·∫øn tr√¨nh v√† lu·ªìng l√† c√°c th√†nh ph·∫ßn c∆° b·∫£n trong h·ªá ƒëi·ªÅu h√†nh. Ti·∫øn tr√¨nh l√† m·ªôt ch∆∞∆°ng tr√¨nh ƒëang ƒë∆∞·ª£c th·ª±c thi trong khi lu·ªìng l√† m·ªôt ph·∫ßn c·ªßa ti·∫øn tr√¨nh. Lu·ªìng cho ph√©p m·ªôt ch∆∞∆°ng tr√¨nh th·ª±c hi·ªán nhi·ªÅu t√°c v·ª• c√πng l√∫c, nh∆∞ t·∫£i xu·ªëng t·ªáp trong khi b·∫°n duy·ªát trang web ho·∫∑c ch·∫°y ho·∫°t ·∫£nh trong khi x·ª≠ l√Ω ƒë·∫ßu v√†o c·ªßa ng∆∞·ªùi d√πng. M·ªôt ti·∫øn tr√¨nh c√≥ th·ªÉ bao g·ªìm nhi·ªÅu lu·ªìng. Trong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω kh√°m ph√° s·ª± kh√°c bi·ªát gi·ªØa ti·∫øn tr√¨nh v√† lu·ªìng m·ªôt c√°ch chi ti·∫øt.

### Quy tr√¨nh l√† g√¨?
Ti·∫øn tr√¨nh v·ªÅ c∆° b·∫£n l√† c√°c ch∆∞∆°ng tr√¨nh ƒë∆∞·ª£c ph√¢n ph·ªëi t·ª´ tr·∫°ng th√°i s·∫µn s√†ng v√† ƒë∆∞·ª£c l√™n l·ªãch trong CPU ƒë·ªÉ th·ª±c thi. **PCB** (Kh·ªëi ƒëi·ªÅu khi·ªÉn ti·∫øn tr√¨nh) gi·ªØ ng·ªØ c·∫£nh c·ªßa ti·∫øn tr√¨nh. M·ªôt ti·∫øn tr√¨nh c√≥ th·ªÉ t·∫°o ra c√°c ti·∫øn tr√¨nh kh√°c ƒë∆∞·ª£c g·ªçi l√† Ti·∫øn tr√¨nh con. Ti·∫øn tr√¨nh m·∫•t nhi·ªÅu th·ªùi gian h∆°n ƒë·ªÉ k·∫øt th√∫c v√† n√≥ b·ªã c√¥ l·∫≠p c√≥ nghƒ©a l√† n√≥ kh√¥ng chia s·∫ª b·ªô nh·ªõ v·ªõi b·∫•t k·ª≥ ti·∫øn tr√¨nh n√†o kh√°c. Ti·∫øn tr√¨nh c√≥ th·ªÉ c√≥ c√°c tr·∫°ng th√°i sau: m·ªõi, s·∫µn s√†ng, ƒëang ch·∫°y, ƒëang ch·ªù, ƒë√£ k·∫øt th√∫c v√† b·ªã treo.

ƒê·ªçc th√™m v·ªÅ Gi·ªõi thi·ªáu v·ªÅ Qu·∫£n l√Ω quy tr√¨nh.

### Thread l√† g√¨?
Lu·ªìng th∆∞·ªùng ƒë∆∞·ª£c g·ªçi l√† "quy tr√¨nh nh·∫π" v√¨ ch√∫ng chia s·∫ª m·ªôt s·ªë t√≠nh nƒÉng c·ªßa quy tr√¨nh nh∆∞ng nh·ªè h∆°n v√† nhanh h∆°n. M·ªói lu·ªìng lu√¥n l√† m·ªôt ph·∫ßn c·ªßa m·ªôt quy tr√¨nh c·ª• th·ªÉ. M·ªôt lu·ªìng c√≥ ba tr·∫°ng th√°i: ƒêang ch·∫°y, S·∫µn s√†ng v√† B·ªã ch·∫∑n.

M·ªôt lu·ªìng m·∫•t √≠t th·ªùi gian h∆°n ƒë·ªÉ k·∫øt th√∫c so v·ªõi m·ªôt ti·∫øn tr√¨nh nh∆∞ng kh√¥ng gi·ªëng nh∆∞ ti·∫øn tr√¨nh, c√°c lu·ªìng kh√¥ng c√¥ l·∫≠p.

### V√≠ d·ª•:
H√£y t∆∞·ªüng t∆∞·ª£ng m·ªôt tr√¨nh x·ª≠ l√Ω vƒÉn b·∫£n ho·∫°t ƒë·ªông v·ªõi hai t√°c v·ª• ri√™ng bi·ªát di·ªÖn ra c√πng l√∫c. M·ªôt t√°c v·ª• t·∫≠p trung v√†o vi·ªác t∆∞∆°ng t√°c v·ªõi ng∆∞·ªùi d√πng, nh∆∞ ph·∫£n h·ªìi khi nh·∫≠p ho·∫∑c cu·ªôn, trong khi t√°c v·ª• kia ho·∫°t ƒë·ªông ·ªü ch·∫ø ƒë·ªô n·ªÅn ƒë·ªÉ ƒëi·ªÅu ch·ªânh ƒë·ªãnh d·∫°ng c·ªßa to√†n b·ªô t√†i li·ªáu.

V√≠ d·ª•, n·∫øu b·∫°n x√≥a m·ªôt c√¢u tr√™n trang 1, t√°c v·ª• t·∫≠p trung v√†o ng∆∞·ªùi d√πng s·∫Ω ngay l·∫≠p t·ª©c y√™u c·∫ßu t√°c v·ª• n·ªÅn ƒë·ªãnh d·∫°ng l·∫°i to√†n b·ªô cu·ªën s√°ch. Trong khi t√°c v·ª• n·ªÅn ƒëang b·∫≠n ƒë·ªãnh d·∫°ng l·∫°i, t√°c v·ª• t·∫≠p trung v√†o ng∆∞·ªùi d√πng v·∫´n ti·∫øp t·ª•c x·ª≠ l√Ω c√°c h√†nh ƒë·ªông ƒë∆°n gi·∫£n nh∆∞ cho ph√©p b·∫°n cu·ªôn qua trang 1 ho·∫∑c nh·∫•p v√†o c√°c m·ª•c.

Khi b·∫°n s·ª≠ d·ª•ng tr√¨nh duy·ªát web, c√°c lu·ªìng s·∫Ω ho·∫°t ƒë·ªông ·∫©n ƒë·ªÉ x·ª≠ l√Ω nhi·ªÅu t√°c v·ª• kh√°c nhau c√πng l√∫c.
V√≠ d·ª•:
- M·ªôt lu·ªìng ƒëang t·∫£i n·ªôi dung trang web (vƒÉn b·∫£n, h√¨nh ·∫£nh, video).
- M·ªôt lu·ªìng kh√°c ƒëang ph·∫£n h·ªìi c√°c h√†nh ƒë·ªông c·ªßa b·∫°n nh∆∞ cu·ªôn, nh·∫•p ho·∫∑c nh·∫≠p.
- M·ªôt lu·ªìng ri√™ng bi·ªát c√≥ th·ªÉ ƒëang ch·∫°y JavaScript ƒë·ªÉ l√†m cho trang web t∆∞∆°ng t√°c.

ƒêa nhi·ªám n√†y l√†m cho tr√¨nh duy·ªát m∆∞·ª£t m√† v√† ph·∫£n h·ªìi nhanh. V√≠ d·ª•, b·∫°n c√≥ th·ªÉ cu·ªôn qua m·ªôt trang ho·∫∑c nh·∫≠p v√†o thanh t√¨m ki·∫øm trong khi ph·∫ßn c√≤n l·∫°i c·ªßa trang v·∫´n ƒëang t·∫£i. N·∫øu lu·ªìng kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng, tr√¨nh duy·ªát s·∫Ω ƒë√≥ng bƒÉng v√† ƒë·ª£i m·ªôt t√°c v·ª• ho√†n t·∫•t tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu t√°c v·ª• kh√°c. Lu·ªìng ƒë·∫£m b·∫£o m·ªçi th·ª© di·ªÖn ra nhanh ch√≥ng v√† li·ªÅn m·∫°ch.

<p align="right" width="80%">
    <img width="10%" src="https://media.geeksforgeeks.org/wp-content/uploads/20190522155604/Untitled-Diagram-361.png"> 
</p>

### S·ª± kh√°c bi·ªát gi·ªØa Process v√† Thread
B·∫£ng d∆∞·ªõi ƒë√¢y th·ªÉ hi·ªán s·ª± kh√°c bi·ªát gi·ªØa ti·∫øn tr√¨nh v√† lu·ªìng.

| Ti√™u ch√≠                     | Ti·∫øn Tr√¨nh (Process)                                    | Lu·ªìng (Thread)                                    |
|------------------------------|---------------------------------------------------------|---------------------------------------------------|
| **Kh√°i ni·ªám**                | Ti·∫øn tr√¨nh c√≥ nghƒ©a l√† m·ªôt ch∆∞∆°ng tr√¨nh ƒëang ƒë∆∞·ª£c th·ª±c thi. | Lu·ªìng c√≥ nghƒ©a l√† m·ªôt ph√¢n ƒëo·∫°n c·ªßa m·ªôt qu√° tr√¨nh. |
| **Th·ªùi gian k·∫øt th√∫c**        | M·ªôt ti·∫øn tr√¨nh m·∫•t nhi·ªÅu th·ªùi gian h∆°n ƒë·ªÉ k·∫øt th√∫c.    | M·ªôt lu·ªìng m·∫•t √≠t th·ªùi gian h∆°n ƒë·ªÉ k·∫øt th√∫c.       |
| **Th·ªùi gian t·∫°o ra**          | Ph·∫£i m·∫•t nhi·ªÅu th·ªùi gian h∆°n ƒë·ªÉ t·∫°o ra.                | M·∫•t √≠t th·ªùi gian h∆°n ƒë·ªÉ t·∫°o ra.                   |
| **Chuy·ªÉn ƒë·ªïi ng·ªØ c·∫£nh**       | Vi·ªác chuy·ªÉn ƒë·ªïi ng·ªØ c·∫£nh c≈©ng m·∫•t nhi·ªÅu th·ªùi gian h∆°n. | Chuy·ªÉn ƒë·ªïi ng·ªØ c·∫£nh m·∫•t √≠t th·ªùi gian h∆°n.         |
| **Giao ti·∫øp gi·ªØa c√°c ƒë∆°n v·ªã**| Ti·∫øn tr√¨nh k√©m hi·ªáu qu·∫£ h∆°n v·ªÅ m·∫∑t giao ti·∫øp.           | Lu·ªìng c√≥ hi·ªáu qu·∫£ h∆°n v·ªÅ m·∫∑t giao ti·∫øp.           |
| **ƒêa nhi·ªám**                  | ƒêa l·∫≠p tr√¨nh bao g·ªìm c√°c kh√°i ni·ªám v·ªÅ ƒëa ti·∫øn tr√¨nh.    | Ch√∫ng ta kh√¥ng c·∫ßn nhi·ªÅu ch∆∞∆°ng tr√¨nh ho·∫°t ƒë·ªông cho nhi·ªÅu lu·ªìng v√¨ m·ªôt ti·∫øn tr√¨nh duy nh·∫•t bao g·ªìm nhi·ªÅu lu·ªìng. |
| **B·ªô nh·ªõ**                    | M·ªói ti·∫øn tr√¨nh ch·∫°y trong b·ªô nh·ªõ ri√™ng c·ªßa n√≥.          | C√°c lu·ªìng chia s·∫ª b·ªô nh·ªõ.                         |
| **Tr·ªçng l∆∞·ª£ng**               | M·ªôt ti·∫øn tr√¨nh n·∫∑ng h∆°n so v·ªõi m·ªôt lu·ªìng.              | Lu·ªìng r·∫•t nh·∫π v√¨ m·ªói lu·ªìng trong m·ªôt ti·∫øn tr√¨nh ƒë·ªÅu chia s·∫ª m√£, d·ªØ li·ªáu v√† t√†i nguy√™n. |
| **Chuy·ªÉn ƒë·ªïi**                | Chuy·ªÉn ƒë·ªïi quy tr√¨nh s·ª≠ d·ª•ng giao di·ªán trong h·ªá ƒëi·ªÅu h√†nh. | Chuy·ªÉn ƒë·ªïi lu·ªìng c√≥ th·ªÉ kh√¥ng c·∫ßn s·ª± tham gia c·ªßa h·ªá ƒëi·ªÅu h√†nh. |
| **·∫¢nh h∆∞·ªüng khi b·ªã ch·∫∑n**     | N·∫øu m·ªôt ti·∫øn tr√¨nh b·ªã ch·∫∑n th√¨ n√≥ s·∫Ω kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn vi·ªác th·ª±c thi c√°c ti·∫øn tr√¨nh kh√°c. | N·∫øu m·ªôt lu·ªìng c·∫•p ng∆∞·ªùi d√πng b·ªã ch·∫∑n, th√¨ t·∫•t c·∫£ c√°c lu·ªìng c·∫•p ng∆∞·ªùi d√πng kh√°c c≈©ng b·ªã ch·∫∑n. |
| **Ng·ªØ c·∫£nh**                  | M·ªói ti·∫øn tr√¨nh c√≥ Kh·ªëi ƒëi·ªÅu khi·ªÉn ti·∫øn tr√¨nh, NgƒÉn x·∫øp v√† Kh√¥ng gian ƒë·ªãa ch·ªâ ri√™ng. | Lu·ªìng c√≥ PCB cha, Kh·ªëi ƒëi·ªÅu khi·ªÉn lu·ªìng ri√™ng, NgƒÉn x·∫øp v√† kh√¥ng gian ƒê·ªãa ch·ªâ chung. |
| **S·ª± thay ƒë·ªïi**               | Nh·ªØng thay ƒë·ªïi ·ªü ti·∫øn tr√¨nh cha kh√¥ng ·∫£nh h∆∞·ªüng t·ªõi ti·∫øn tr√¨nh con. | V√¨ t·∫•t c·∫£ c√°c lu·ªìng c·ªßa c√πng m·ªôt ti·∫øn tr√¨nh chia s·∫ª kh√¥ng gian ƒë·ªãa ch·ªâ v√† c√°c t√†i nguy√™n kh√°c n√™n b·∫•t k·ª≥ thay ƒë·ªïi n√†o ƒë·ªëi v·ªõi lu·ªìng ch√≠nh ƒë·ªÅu c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn h√†nh vi c·ªßa c√°c lu·ªìng kh√°c c·ªßa ti·∫øn tr√¨nh. |
| **L·ªánh g·ªçi h·ªá th·ªëng**         | C√≥ m·ªôt l·ªánh g·ªçi h·ªá th·ªëng li√™n quan ƒë·∫øn vi·ªác n√†y.        | Kh√¥ng c·∫ßn l·ªánh g·ªçi h·ªá th·ªëng n√†o c·∫£, n√≥ ƒë∆∞·ª£c t·∫°o ra b·∫±ng c√°ch s·ª≠ d·ª•ng API. |
| **Chia s·∫ª d·ªØ li·ªáu**           | M·ªói ti·∫øn tr√¨nh kh√¥ng chia s·∫ª d·ªØ li·ªáu v·ªõi nhau.          | C√°c lu·ªìng chia s·∫ª d·ªØ li·ªáu v·ªõi nhau.               |

### ∆Øu ƒëi·ªÉm c·ªßa quy tr√¨nh
- C√°c quy tr√¨nh ho·∫°t ƒë·ªông ƒë·ªôc l·∫≠p trong b·ªô nh·ªõ ri√™ng, ƒë·∫£m b·∫£o kh√¥ng b·ªã can thi·ªáp v√† b·∫£o m·∫≠t t·ªët h∆°n.
- C√°c t√†i nguy√™n nh∆∞ CPU ‚Äã‚Äãv√† b·ªô nh·ªõ ƒë∆∞·ª£c ph√¢n b·ªï hi·ªáu qu·∫£ ƒë·ªÉ t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t.
- C√°c quy tr√¨nh c√≥ th·ªÉ ƒë∆∞·ª£c ∆∞u ti√™n ƒë·ªÉ ƒë·∫£m b·∫£o c√°c nhi·ªám v·ª• quan tr·ªçng nh·∫≠n ƒë∆∞·ª£c ƒë·ªß ngu·ªìn l·ª±c c·∫ßn thi·∫øt.

### Nh∆∞·ª£c ƒëi·ªÉm c·ªßa quy tr√¨nh
- Vi·ªác chuy·ªÉn ƒë·ªïi th∆∞·ªùng xuy√™n gi·ªØa c√°c quy tr√¨nh c√≥ th·ªÉ l√†m ch·∫≠m h·ªá th·ªëng v√† gi·∫£m t·ªëc ƒë·ªô.
- Qu·∫£n l√Ω t√†i nguy√™n kh√¥ng ƒë√∫ng c√°ch c√≥ th·ªÉ g√¢y ra t√¨nh tr·∫°ng b·∫ø t·∫Øc khi c√°c quy tr√¨nh ng·ª´ng ho·∫°t ƒë·ªông v√† c·∫£n tr·ªü ti·∫øn ƒë·ªô.
- C√≥ qu√° nhi·ªÅu ti·∫øn tr√¨nh c√≥ th·ªÉ khi·∫øn b·∫£ng ti·∫øn tr√¨nh chi·∫øm nhi·ªÅu b·ªô nh·ªõ. ƒêi·ªÅu n√†y c≈©ng c√≥ th·ªÉ khi·∫øn vi·ªác t√¨m ki·∫øm ho·∫∑c c·∫≠p nh·∫≠t b·∫£ng ch·∫≠m h∆°n, c√≥ th·ªÉ l√†m gi·∫£m hi·ªáu su·∫•t h·ªá th·ªëng.

### ∆Øu ƒëi·ªÉm c·ªßa lu·ªìng
- Khi c√≥ nhi·ªÅu c√¥ng vi·ªác t√≠nh to√°n v√† nh·∫≠p/xu·∫•t (I/O), c√°c lu·ªìng s·∫Ω gi√∫p c√°c t√°c v·ª• ch·∫°y c√πng l√∫c, gi√∫p ·ª©ng d·ª•ng ch·∫°y nhanh h∆°n.
- M·ªôt l·ª£i th·∫ø kh√°c c·ªßa vi·ªác s·ª≠ d·ª•ng lu·ªìng l√† v√¨ ch√∫ng nh·∫π h∆°n ti·∫øn tr√¨nh n√™n vi·ªác t·∫°o v√† h·ªßy ch√∫ng d·ªÖ d√†ng h∆°n (t·ª©c l√† nhanh h∆°n) so v·ªõi ti·∫øn tr√¨nh.
- Nhi·ªÅu ·ª©ng d·ª•ng c·∫ßn x·ª≠ l√Ω nhi·ªÅu t√°c v·ª• kh√°c nhau c√πng l√∫c. V√≠ d·ª•, tr√¨nh duy·ªát web c√≥ th·ªÉ t·∫£i trang web, ph√°t video v√† cho ph√©p b·∫°n cu·ªôn t·∫•t c·∫£ c√πng m·ªôt l√∫c. Lu·ªìng gi√∫p th·ª±c hi·ªán ƒëi·ªÅu n√†y b·∫±ng c√°ch chia c√°c t√°c v·ª• n√†y th√†nh c√°c ph·∫ßn nh·ªè h∆°n c√≥ th·ªÉ ch·∫°y c√πng nhau.

### Nh∆∞·ª£c ƒëi·ªÉm c·ªßa lu·ªìng
- C√°c lu·ªìng trong c√πng m·ªôt ti·∫øn tr√¨nh kh√¥ng ho√†n to√†n ƒë·ªôc l·∫≠p nh∆∞ c√°c ti·∫øn tr√¨nh ri√™ng bi·ªát. Ch√∫ng chia s·∫ª c√πng m·ªôt kh√¥ng gian b·ªô nh·ªõ bao g·ªìm c√°c bi·∫øn to√†n c·ª•c. ƒêi·ªÅu n√†y c√≥ nghƒ©a l√† m·ªôt lu·ªìng c√≥ th·ªÉ v√¥ t√¨nh thay ƒë·ªïi ho·∫∑c th·∫≠m ch√≠ x√≥a d·ªØ li·ªáu c·ªßa lu·ªìng kh√°c v√¨ kh√¥ng c√≥ s·ª± b·∫£o v·ªá n√†o gi·ªØa ch√∫ng.
- C√°c lu·ªìng c≈©ng chia s·∫ª t√†i nguy√™n nh∆∞ t·ªáp. V√≠ d·ª• ‚Äì n·∫øu m·ªôt lu·ªìng ƒë√≥ng t·ªáp trong khi lu·ªìng kh√°c v·∫´n ƒëang s·ª≠ d·ª•ng t·ªáp ƒë√≥, ƒëi·ªÅu n√†y c√≥ th·ªÉ g√¢y ra l·ªói ho·∫∑c h√†nh vi kh√¥ng mong mu·ªën.
- N·∫øu t·∫°o qu√° nhi·ªÅu lu·ªìng, ch√∫ng c√≥ th·ªÉ l√†m ch·∫≠m h·ªá th·ªëng ho·∫∑c khi·∫øn h·ªá th·ªëng h·∫øt b·ªô nh·ªõ.

### Ph·∫ßn k·∫øt lu·∫≠n
T·ª´ th·∫£o lu·∫≠n tr√™n, ch√∫ng ta c√≥ th·ªÉ k·∫øt lu·∫≠n r·∫±ng **ti·∫øn tr√¨nh** l√† ch∆∞∆°ng tr√¨nh ƒëang th·ª±c thi m·∫•t nhi·ªÅu th·ªùi gian h∆°n ƒë·ªÉ t·∫°o c≈©ng nh∆∞ k·∫øt th√∫c trong khi **lu·ªìng** l√† th√†nh ph·∫ßn c·ªßa ti·∫øn tr√¨nh m·∫•t √≠t th·ªùi gian h∆°n ƒë·ªÉ t·∫°o c≈©ng nh∆∞ k·∫øt th√∫c. Ti·∫øn tr√¨nh c√≥ PCB trong khi lu·ªìng c√≥ PCB lu·ªìng ri√™ng c·ªßa ch√∫ng c√πng v·ªõi PCB c·ªßa ti·∫øn tr√¨nh cha.

## 4. ChatGPT training tr√™n Distributed System
##### ChatGPT: b·∫£n ch·∫•t ChatGPT ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o?

Source: https://phanxuanphucnd.github.io/

ChatGPT l√† m·ªôt Large Language Model (LLM) m·ªõi nh·∫•t c·ªßa OpenAI v√† cho th·∫•y ƒë∆∞·ª£c s·ª± c·∫£i thi·ªán ƒë√°ng k·ªÉ v·ªõi m√¥ h√¨nh ti·ªÅn nhi·ªám c·ªßa n√≥ GPT-3. T∆∞∆°ng t·ª± nh∆∞ nhi·ªÅu LLMs, ChatGPT c√≥ kh·∫£ nƒÉng sinh vƒÉn b·∫£n (text) theo nhi·ªÅu phong c√°ch kh√°c nhau v√† cho nhi·ªÅu m·ª•c ƒë√≠ch kh√°c nhau, nh∆∞ng ChatGPT cho th·∫•y ƒë∆∞·ª£c kh·∫£ nƒÉng v·ªÅ ƒë·ªô ch√≠nh x√°c, chi ti·∫øt v√† m·∫°ch l·∫°c h∆°n r·∫•t ƒë√°ng k·ªÉ. ChatGPT ƒëang l√† xu h∆∞·ªõng, n√≥ nh∆∞ ƒë·∫°i di·ªán cho th·∫ø h·ªá ti·∫øp theo c·ªßa LLMs, t·∫≠p trung m·∫°nh v√†o s·ª± t∆∞∆°ng t√°c trong h·ªôi tho·∫°i (interative conversations).

OpenAI h·ªç ƒë√£ s·ª≠ d·ª•ng k·∫øt h·ª£p c·∫£ Supervised Learning (h·ªçc gi√°m s√°t) v√† Reinforment Learning (h·ªçc tƒÉng c∆∞·ªùng) ƒë·ªÉ tinh ch·ªânh (fine-tune) ChatGPT,** nh∆∞ng Reinforcement Learning m·ªõi l√† th√†nh ph·∫ßn l√†m cho ChatGPT tr·ªü n√™n ƒë·ªôc ƒë√°o h∆°n t·∫•t c·∫£**. K·ªπ thu·∫≠t c·ª• th·ªÉ ƒë∆∞·ª£c g·ªçi l√†** Reinforcement Learning from Human Feedback (RLHF)**, t·ª©c l√† h·ªçc tƒÉng c∆∞·ªùng t·ª´ nh·ªØng d·ªØ li·ªáu feedback c·ªßa con ng∆∞·ªùi, s·ª≠ d·ª•ng v√≤ng l·∫∑p feedback c·ªßa con ng∆∞·ªùi trong qu√° tr√¨nh hu·∫•n luy·ªán ƒë·ªÉ gi·∫£m thi·ªÉu vi·ªác ƒë∆∞a ra c√°c ph·∫£n h·ªìi c√≥ h·∫°i, kh√¥ng trung th·ª±c hay l√† sai l·ªách tri th·ª©c.

### Kh√°i ni·ªám Capability v√† Alignment
![Web v√† ·ª©ng d·ª•ng di ƒë·ªông](https://images.viblo.asia/4ef9b71a-2f9d-41b7-a4ac-e63d8238ef90.png)
ƒê·∫ßu ti·ªÅn ch√∫ng ta c·∫ßn hi·ªÉu 2 kh√°i ni·ªám Capability v√† Alignment trong machine learning. Kh√°i ni·ªám Capability ƒë·ªÅ c·∫≠p t·ªõi kh·∫£ nƒÉng c·ªßa m·ªôt model ƒë·ªÉ th·ª±c hi·ªán m·ªôt ho·∫∑c nhi·ªÅu task c·ª• th·ªÉ. Kh·∫£ nƒÉng c·ªßa m·ªôt model c·ª• th·ªÉ ƒë∆∞·ª£c ƒë√°nh gi√° b·ªüi kh·∫£ nƒÉng t·ªëi ∆∞u objective-function (h√†m t·ªëi ∆∞u/ h√†m m·ª•c ti√™u) c·ªßa n√≥ t·ªët nh∆∞ th·∫ø n√†o?

  V√≠ d·ª• nh∆∞, m·ªôt model ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ d·ª± ƒëo√°n gi√° c·ªßa th·ªã tr∆∞·ªùng ch·ª©ng kho√°n ph·∫£i c√≥ m·ªôt h√†m m·ª•c ti√™u n√†o ƒë√≥ ƒëo ƒë∆∞·ª£c ƒë·ªô ch√≠nh x√°c c√°c d·ª± ƒëo√°n c·ªßa model. N·∫øu model c√≥ kh·∫£ nƒÉng d·ª± ƒëo√°n ch√≠nh x√°c s·ª± bi·∫øn ƒë·ªông gi√° ch·ª©ng kho√°n theo th·ªùi gian, th√¨ ƒë∆∞·ª£c xem l√† c√≥ kh·∫£ nƒÉng capability cao cho task n√†y.

M·∫∑t kh√°c, Alignment li√™n quan t·ªõi nh·ªØng g√¨ m√† ch√∫ng ta th·ª±c s·ª± mu·ªën model l√†m so v·ªõi **nh·ªØng g√¨ m√† model ƒëang ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ l√†m**.

C√°c LLMs ch·∫≥ng h·∫°n nh∆∞ GPT3, LLaMA, BLOOM, PaLM, ... ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n m·ªôt l∆∞·ª£ng r·∫•t l·ªõn d·ªØ li·ªáu text t·ª´ internet v√† c√≥ kh·∫£ nƒÉng sinh vƒÉn b·∫£n gi·ªëng nh∆∞ con ng∆∞·ªùi, nh∆∞ng kh√¥ng ph·∫£i l√∫c n√†o LLMs c≈©ng sinh ra ƒë∆∞·ª£c ƒë·∫ßu ra nh∆∞ k·ª≥ v·ªçng c·ªßa con ng∆∞·ªùi ho·∫∑c c√≥ t√≠nh ch√≠nh x√°c. Trong th·ª±c t·∫ø, h√†m m·ª•c ti√™u c·ªßa ch√∫ng l√† ph√¢n ph·ªëi x√°c su·∫•t tr√™n c√°c chu·ªói t·ª´ (word sequences) ho·∫∑c tr√™n chu·ªói token (token sequences) m√† cho ph√©p d·ª± ƒëo√°n ch√≠nh x√°c t·ª´ ti·∫øp theo trong chu·ªói
#### Capability (NƒÉng l·ª±c)
- Kh·∫£ nƒÉng c·ªßa m·ªôt m√¥ h√¨nh th·ª±c hi·ªán m·ªôt ho·∫∑c nhi·ªÅu t√°c v·ª• c·ª• th·ªÉ.
- ƒê∆∞·ª£c ƒë√°nh gi√° d·ª±a tr√™n vi·ªác m√¥ h√¨nh t·ªëi ∆∞u **h√†m m·ª•c ti√™u (objective function)** nh∆∞ th·∫ø n√†o.
- **V√≠ d·ª•:** D·ª± ƒëo√°n gi√° ch·ª©ng kho√°n ch√≠nh x√°c -> capability cao trong t√°c v·ª• ƒë√≥.

#### Alignment (CƒÉn ch·ªânh)
- M·ª©c ƒë·ªô ph√π h·ª£p gi·ªØa **h√†nh vi c·ªßa m√¥ h√¨nh** v√† **√Ω ƒë·ªãnh th·ª±c t·∫ø c·ªßa con ng∆∞·ªùi**.
- C√¢u h·ªèi ƒë·∫∑t ra: *"H√†m m·ª•c ti√™u m√† m√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán c√≥ th·ª±c s·ª± ph·∫£n √°nh ƒëi·ªÅu con ng∆∞·ªùi mu·ªën kh√¥ng?"*
- **V√≠ d·ª• sai l·ªách (misalignment):**
  - D√πng log loss ƒë·ªÉ hu·∫•n luy·ªán model ph√¢n lo·∫°i chim, nh∆∞ng ng∆∞·ªùi d√πng l·∫°i mu·ªën accuracy cao.
  - M·∫∑c d√π log loss th·∫•p ‚Üí model c√≥ capability cao, nh∆∞ng accuracy th·∫•p ‚Üí alignment k√©m.

---

### H·ªá th·ªëng ph√¢n t√°n trong hu·∫•n luy·ªán

Hu·∫•n luy·ªán m·ªôt m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn nh∆∞ ChatGPT (d·ª±a tr√™n GPT-3, GPT-4) ƒë√≤i h·ªèi s·ª≠ d·ª•ng h√†ng ng√†n GPU ho·∫°t ƒë·ªông ƒë·ªìng th·ªùi. V√¨ v·∫≠y, OpenAI v√† c√°c t·ªï ch·ª©c ph√°t tri·ªÉn LLM ph·∫£i √°p d·ª•ng nhi·ªÅu chi·∫øn l∆∞·ª£c **ph√¢n t√°n (distributed)** ƒë·ªÉ tƒÉng hi·ªáu qu·∫£, ƒë·∫£m b·∫£o kh·∫£ nƒÉng m·ªü r·ªông v√† s·ª≠ d·ª•ng t√†i nguy√™n t·ªëi ∆∞u.

##### a. Song song h√≥a d·ªØ li·ªáu (Data Parallelism)

- M·ªói b·∫£n sao c·ªßa m√¥ h√¨nh ƒë∆∞·ª£c ƒë·∫∑t tr√™n m·ªôt GPU kh√°c nhau.
- T·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán ƒë∆∞·ª£c chia nh·ªè th√†nh c√°c batch, m·ªói GPU nh·∫≠n m·ªôt batch kh√°c nhau.
- M·ªói GPU th·ª±c hi·ªán lan truy·ªÅn xu√¥i (forward pass) v√† lan truy·ªÅn ng∆∞·ª£c (backward pass) tr√™n batch c·ªßa n√≥.
- Sau khi t√≠nh gradient, c√°c GPU ƒë·ªìng b·ªô h√≥a tr·ªçng s·ªë v·ªõi nhau (th∆∞·ªùng qua **AllReduce**).

> üìå V√≠ d·ª•: N·∫øu c√≥ 8 GPU, m·ªói GPU s·∫Ω x·ª≠ l√Ω 1/8 t·∫≠p d·ªØ li·ªáu trong m·ªôt v√≤ng l·∫∑p, sau ƒë√≥ t·ªïng h·ª£p k·∫øt qu·∫£ l·∫°i ƒë·ªÉ c·∫≠p nh·∫≠t m√¥ h√¨nh.

##### b. Song song h√≥a m√¥ h√¨nh (Model Parallelism)

- M√¥ h√¨nh qu√° l·ªõn ƒë·ªÉ ch·ª©a tr√™n m·ªôt GPU ƒë∆°n l·∫ª ‚Üí chia c√°c l·ªõp c·ªßa m√¥ h√¨nh ho·∫∑c t·ª´ng ph·∫ßn c·ªßa layer cho nhi·ªÅu GPU kh√°c nhau.
- C√°c GPU trao ƒë·ªïi d·ªØ li·ªáu trung gian (activations) khi lan truy·ªÅn xu√¥i ho·∫∑c ng∆∞·ª£c.

> üìå V√≠ d·ª•: Layer 1 ‚Üí GPU A, Layer 2 ‚Üí GPU B, Layer 3 ‚Üí GPU C‚Ä¶

##### c. Pipeline Parallelism (D√≤ng x·ª≠ l√Ω song song)

- M√¥ h√¨nh ƒë∆∞·ª£c chia th√†nh c√°c ƒëo·∫°n (stage), m·ªói ƒëo·∫°n ch·∫°y tr√™n m·ªôt GPU.
- C√°c mini-batch ƒë∆∞·ª£c x·∫øp theo pipeline (·ªëng chuy·ªÅn) ‚Üí GPU n√†o c≈©ng lu√¥n b·∫≠n r·ªôn, kh√¥ng b·ªã ch·ªù ƒë·ª£i qu√° nhi·ªÅu.

> üìå ∆Øu ƒëi·ªÉm: Gi·∫£m ƒë·ªô tr·ªÖ (latency) so v·ªõi Model Parallelism thu·∫ßn t√∫y.

##### d. Hu·∫•n luy·ªán k·∫øt h·ª£p (Hybrid Parallelism)

- K·∫øt h·ª£p **Data + Model + Pipeline Parallelism** ƒë·ªÉ t·∫≠n d·ª•ng t·ªëi ƒëa t√†i nguy√™n.
- ƒê∆∞·ª£c s·ª≠ d·ª•ng trong c√°c m√¥ h√¨nh kh·ªïng l·ªì nh∆∞ GPT-3 (175B parameters) ho·∫∑c GPT-4.

> üìå V√≠ d·ª•: T·∫≠p d·ªØ li·ªáu chia theo Data Parallelism, m√¥ h√¨nh chia theo Model Parallelism, v√† c√°c t·∫ßng ƒë∆∞·ª£c x·ª≠ l√Ω theo pipeline.

##### e. Zero Redundancy Optimizer (ZeRO)

- ƒê∆∞·ª£c gi·ªõi thi·ªáu b·ªüi Microsoft trong DeepSpeed.
- Ph√¢n t√°n th√¥ng tin v·ªÅ optimizer, gradients v√† tr·∫°ng th√°i m√¥ h√¨nh ‚Üí gi·∫£m m·ª©c s·ª≠ d·ª•ng b·ªô nh·ªõ tr√™n m·ªói GPU ‚Üí c√≥ th·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh l·ªõn h∆°n nhi·ªÅu l·∫ßn.

> üìå GPT-3 c√≥ th·ªÉ kh√¥ng d√πng ZeRO, nh∆∞ng GPT-4 ho·∫∑c c√°c m√¥ h√¨nh hi·ªán ƒë·∫°i sau n√†y ƒë·ªÅu t·∫≠n d·ª•ng k·ªπ thu·∫≠t n√†y.

---

### 3. T·ªëi ∆∞u h√≥a hi·ªáu su·∫•t hu·∫•n luy·ªán

Hu·∫•n luy·ªán c√°c m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn (LLMs) nh∆∞ GPT-3, GPT-4, LLaMA, PaLM,‚Ä¶ ƒë√≤i h·ªèi r·∫•t nhi·ªÅu t√†i nguy√™n v√† th·ªùi gian. V√¨ v·∫≠y, vi·ªác **t·ªëi ∆∞u hi·ªáu su·∫•t hu·∫•n luy·ªán** l√† c·ª±c k·ª≥ quan tr·ªçng ƒë·ªÉ gi·∫£m chi ph√≠, tƒÉng t·ªëc ƒë·ªô v√† ƒë·∫°t hi·ªáu qu·∫£ t·ªëi ƒëa t·ª´ ph·∫ßn c·ª©ng. C√°c chi·∫øn l∆∞·ª£c d∆∞·ªõi ƒë√¢y th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng:

---

##### a. Mixed Precision Training (Hu·∫•n luy·ªán v·ªõi ƒë·ªô ch√≠nh x√°c h·ªón h·ª£p)

- S·ª≠ d·ª•ng **FP16 (half-precision)** ho·∫∑c **bfloat16** thay cho **FP32 (single-precision)**.
- ∆Øu ƒëi·ªÉm:
  - Gi·∫£m b·ªô nh·ªõ GPU ti√™u th·ª•.
  - TƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω v√¨ ph·∫ßn c·ª©ng nh∆∞ NVIDIA A100 c√≥ h·ªó tr·ª£ ph·∫ßn c·ª©ng FP16.
  - Cho ph√©p hu·∫•n luy·ªán m√¥ h√¨nh l·ªõn h∆°n tr√™n c√πng GPU.

> üìå Th∆∞ vi·ªán h·ªó tr·ª£: `NVIDIA Apex`, `DeepSpeed`, `Transformers` c·ªßa Hugging Face (`Trainer` h·ªó tr·ª£ `fp16=True`)

---

##### b. Gradient Accumulation

- Khi batch size l·ªõn kh√¥ng v·ª´a v√†o b·ªô nh·ªõ GPU, chia th√†nh nhi·ªÅu mini-batch nh·ªè v√† t√≠ch l≈©y gradient qua nhi·ªÅu v√≤ng r·ªìi m·ªõi c·∫≠p nh·∫≠t tr·ªçng s·ªë.
- ∆Øu ƒëi·ªÉm:
  - Gi·ªØ ƒë∆∞·ª£c hi·ªáu qu·∫£ c·ªßa batch size l·ªõn.
  - T·ªëi ∆∞u hi·ªáu qu·∫£ s·ª≠ d·ª•ng GPU h·∫°n ch·∫ø b·ªô nh·ªõ.

---

##### c. Gradient Checkpointing

- Thay v√¨ l∆∞u to√†n b·ªô intermediate activations trong qu√° tr√¨nh forward, ch·ªâ l∆∞u m·ªôt ph·∫ßn v√† t√≠nh to√°n l·∫°i khi c·∫ßn trong backward.
- ∆Øu ƒëi·ªÉm:
  - Gi·∫£m l∆∞·ª£ng b·ªô nh·ªõ d√πng ƒë·ªÉ l∆∞u tr·ªØ activations.
  - Cho ph√©p hu·∫•n luy·ªán m√¥ h√¨nh s√¢u h∆°n tr√™n GPU h·∫°n ch·∫ø b·ªô nh·ªõ.

---

##### d. Efficient Optimizers (T·ªëi ∆∞u h√≥a hi·ªáu qu·∫£)

- D√πng c√°c optimizer nh·∫π v√† t·ªëi ∆∞u b·ªô nh·ªõ:
  - **AdamW**, **8-bit Adam** (from `bitsandbytes`)
  - **ZeRO Optimizer** t·ª´ DeepSpeed (ƒë√£ tr√¨nh b√†y ·ªü ph·∫ßn tr∆∞·ªõc)

---

##### e. Caching & Prefetching

- T·∫£i tr∆∞·ªõc v√† l∆∞u cache d·ªØ li·ªáu hu·∫•n luy·ªán v√†o b·ªô nh·ªõ ƒë·ªÉ tr√°nh t√¨nh tr·∫°ng ch·ªù I/O t·ª´ ·ªï c·ª©ng.
- D√πng **dataloader.prefetch_factor**, **num_workers > 0** ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô cung c·∫•p d·ªØ li·ªáu.

---

##### f. Distributed Training Optimization

- S·ª≠ d·ª•ng th∆∞ vi·ªán h·ªó tr·ª£ hu·∫•n luy·ªán ph√¢n t√°n hi·ªáu qu·∫£:
  - `DeepSpeed`
  - `FairScale`
  - `FSDP (Fully Sharded Data Parallel)` t·ª´ PyTorch
  - `Megatron-LM`
  - `Accelerate` t·ª´ Hugging Face

---

##### g. Dynamic Batching

- G·ªôp c√°c input c√≥ ƒë·ªô d√†i g·∫ßn nhau ƒë·ªÉ tr√°nh l√£ng ph√≠ t√†i nguy√™n do padding.
- D√πng `BucketIterator`, `Dynamic Padding`, ho·∫∑c tokenizer c·ªßa Hugging Face v·ªõi `pad_to_multiple_of`.

---

##### h. Profiling & Monitoring

- D√πng c√°c c√¥ng c·ª• nh∆∞:
  - **NVIDIA Nsight Systems / Nsight Compute**
  - **TensorBoard**
  - **WandB**, **Weights & Biases**
  - **PyTorch Profiler**
- M·ª•c ƒë√≠ch: theo d√µi b·ªô nh·ªõ, t·ªëc ƒë·ªô

### T√†i li·ªáu tham kh·∫£o

- [Efficient Training for Transformers ‚Äì Hugging Face](https://huggingface.co/course/chapter6)
- [Mixed Precision Training ‚Äì NVIDIA](https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html)
- [Gradient Checkpointing in PyTorch](https://pytorch.org/docs/stable/checkpoint.html)
- [Accelerate by Hugging Face](https://huggingface.co/docs/accelerate/index)
